{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k0q29Z3ukKI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2f73afc-6ea0-4713-dbc7-d32b65683d33"
      },
      "source": [
        "# delete this cell if working on Pycharm\n",
        "!pip install Bio\n",
        "!pip install import-ipynb"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: Bio in /usr/local/lib/python3.7/dist-packages (1.3.8)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.7/dist-packages (from Bio) (1.79)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.64.0)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.7/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.6)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from mygene->Bio) (0.2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n",
            "Requirement already satisfied: import-ipynb in /usr/local/lib/python3.7/dist-packages (0.1.4)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.5.0)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from import-ipynb) (5.3.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->import-ipynb) (57.4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->import-ipynb) (0.2.5)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (2.15.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.3.3)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat->import-ipynb) (4.10.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (0.18.1)\n",
            "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (5.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.11.3)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (21.4.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->import-ipynb) (4.2.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat->import-ipynb) (3.8.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->import-ipynb) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCeXnsvlLtE-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad79e3aa-6872-40c6-8ef4-6a019f400881"
      },
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "import matplotlib\n",
        "matplotlib.use('nbagg')\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "# so we can import utils notebook (delete if working on Pycharm), you might need to change it to your working directory path\n",
        "\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')\n",
        "!ls\n",
        "%cd \"drive\"\n",
        "%cd \"MyDrive\"\n",
        "%cd \"Ex4Data\"\n",
        "import import_ipynb\n",
        "import utils\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "drive  sample_data\n",
            "/content/drive\n",
            "/content/drive/MyDrive\n",
            "/content/drive/.shortcut-targets-by-id/1o0YBS756Yf3fr4s6rHsprRqjOfdY6PDU/Ex4Data\n",
            "importing Jupyter notebook from utils.ipynb\n",
            "Requirement already satisfied: Bio in /usr/local/lib/python3.7/dist-packages (1.3.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from Bio) (2.23.0)\n",
            "Requirement already satisfied: biopython>=1.79 in /usr/local/lib/python3.7/dist-packages (from Bio) (1.79)\n",
            "Requirement already satisfied: mygene in /usr/local/lib/python3.7/dist-packages (from Bio) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from Bio) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from biopython>=1.79->Bio) (1.21.6)\n",
            "Requirement already satisfied: biothings-client>=0.2.6 in /usr/local/lib/python3.7/dist-packages (from mygene->Bio) (0.2.6)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->Bio) (1.24.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y4fRqWLLwhR"
      },
      "source": [
        "###############################################################################\n",
        "#                                                                             #\n",
        "#              Parameters you can change, but don't have to                   #\n",
        "#                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "# number of ResNet blocks for the first ResNet and the kernel size.\n",
        "RESNET_1_BLOCKS = 3 \n",
        "RESNET_1_KERNEL_SIZE = 15\n",
        "RESNET_1_KERNEL_NUM = 64\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "#                                                                             #\n",
        "#                        Parameters you need to choose                        #\n",
        "#                                                                             #\n",
        "###############################################################################\n",
        "\n",
        "\n",
        "# number of ResNet blocks for the second ResNet, dilation list to repeat and the kernel size.\n",
        "\n",
        "RESNET_2_BLOCKS = 3\n",
        "RESNET_2_KERNEL_SIZE = 3\n",
        "RESNET_2_KERNEL_NUM = 32\n",
        "DILATION = [1, 2, 4, 8]\n",
        "\n",
        "# percentage of dropout for the dropout layer\n",
        "DROPOUT = 0.15\n",
        "\n",
        "# number of epochs, Learning rate and Batch size\n",
        "EPOCHS = 60\n",
        "LR = 0.01\n",
        "BATCH = 32"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7wc4YJMo5V-"
      },
      "source": [
        "def resnet_1(input_layer):  # TODO: implement this!\n",
        "    \"\"\"\n",
        "    ResNet layer - input -> BatchNormalization -> Conv1D -> Relu -> BatchNormalization -> Conv1D -> Relu -> Add\n",
        "    :param input_layer: input layer for the ResNet\n",
        "    :return: last layer of the ResNet\n",
        "    \"\"\"\n",
        "    for _ in range(RESNET_1_BLOCKS):\n",
        "      out_batchnorm = layers.BatchNormalization()(input_layer)\n",
        "      out_conv1 = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same', activation='relu')(out_batchnorm)\n",
        "      out_batchnorm = layers.BatchNormalization()(out_conv1)\n",
        "      out_conv1 = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same', activation='relu')(out_batchnorm)\n",
        "      input_layer = layers.Add()([input_layer, out_conv1])\n",
        "    return input_layer\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXj05_d7o5io"
      },
      "source": [
        "def resnet_2(input_layer):  # TODO: implement this!\n",
        "    \"\"\"\n",
        "    Dilated ResNet layer - input -> BatchNormalization -> dilated Conv1D -> Relu -> BatchNormalization -> dilated Conv1D -> Relu -> Add\n",
        "    :param input_layer: input layer for the ResNet\n",
        "    :return: last layer of the ResNet\n",
        "    \"\"\"\n",
        "    for _ in range(RESNET_2_BLOCKS):\n",
        "      for dilation in DILATION:\n",
        "        out_batchnorm = layers.BatchNormalization()(input_layer)\n",
        "        out_conv1 = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding='same', activation='relu', dilation_rate=dilation)(out_batchnorm)\n",
        "        out_batchnorm = layers.BatchNormalization()(out_conv1)\n",
        "        out_conv1 = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding='same', activation='relu', dilation_rate=dilation)(out_batchnorm)\n",
        "        input_layer = layers.Add()([input_layer, out_conv1])\n",
        "    return input_layer"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_CN7eEopE3A"
      },
      "source": [
        "def build_network():\n",
        "    \"\"\"\n",
        "    builds the neural network architecture as shown in the exercise.\n",
        "    :return: a Keras Model\n",
        "    \"\"\"\n",
        "    ...\n",
        "    # input, shape (NB_MAX_LENGTH,FEATURE_NUM)\n",
        "    input_layer = tf.keras.Input(shape=(utils.NB_MAX_LENGTH, utils.FEATURE_NUM))\n",
        "\n",
        "    # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
        "    conv1d_layer = layers.Conv1D(RESNET_1_KERNEL_NUM, RESNET_1_KERNEL_SIZE, padding='same')(input_layer)\n",
        "\n",
        "    # first ResNet -> shape = (NB_MAX_LENGTH, RESNET_1_KERNEL_NUM)\n",
        "    resnet_layer = resnet_1(conv1d_layer)\n",
        "\n",
        "    # # Conv1D -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    conv1d_layer = layers.Conv1D(RESNET_2_KERNEL_NUM, RESNET_2_KERNEL_SIZE, padding=\"same\")(resnet_layer)\n",
        "\n",
        "    # # second ResNet -> shape = (NB_MAX_LENGTH, RESNET_2_KERNEL_NUM)\n",
        "    resnet_layer = resnet_2(conv1d_layer)\n",
        "\n",
        "    dropout_layer = layers.Dropout(DROPOUT)(resnet_layer)\n",
        "\n",
        "    conv1d_layer = layers.Conv1D(np.ceil(RESNET_2_KERNEL_NUM/2), RESNET_2_KERNEL_SIZE, padding=\"same\", activation='elu')(dropout_layer)\n",
        "\n",
        "    output = layers.Dense(utils.OUTPUT_SIZE)(conv1d_layer)\n",
        "\n",
        "\n",
        "    return tf.keras.Model(input_layer, output, name='from_seq_to_struct')\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8itDQ59HpFlL"
      },
      "source": [
        "def plot_val_train_loss(history):\n",
        "    \"\"\"\n",
        "    plots the train and validation loss of the model at each epoch, saves it in 'model_loss_history.png'\n",
        "    :param history: history object (output of fit function)\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    ig, axes = plt.subplots(1, 1, figsize=(15,3))\n",
        "    axes.plot(history.history['loss'][10:], label='Training loss')\n",
        "    axes.plot(history.history['val_loss'][10:], label='Validation loss')\n",
        "    axes.legend()\n",
        "    axes.set_title(\"Train and Val MSE loss\")\n",
        "\n",
        "    plt.savefig(\"/content/drive/MyDrive/Ex4Data/model_loss_history\")  # TODO: you can change the path here\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TQLxqy33pJk2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f769c10-f792-4d3c-d7bb-6698ad2a51be"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    model = build_network()\n",
        "\n",
        "    # you can load here your input and output data\n",
        "    X = np.load('input_data.npy')\n",
        "    Y = np.load('label_data.npy')\n",
        "\n",
        "    X_train, X_val, y_train, y_val  = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
        "\n",
        "    my_optimizer= tf.keras.optimizers.Adam(learning_rate=LR)\n",
        "    model.compile(optimizer=my_optimizer, loss=\"mse\")\n",
        "    history = model.fit(X_train, y_train, epochs=EPOCHS, batch_size=BATCH, validation_data=(X_val, y_val))\n",
        "\n",
        "    model.save(\"our_model.tf\")\n",
        "    model = tf.keras.models.load_model(\"our_model.tf\")\n",
        "\n",
        "    # part 3 predict\n",
        "    to_predict = utils.generate_input(os.path.join(\"/content/drive/MyDrive/Ex4Data\", \"6xw6.pdb\"))\n",
        "    prediction = model.predict(to_predict[np.newaxis,:,:])\n",
        "    matrix = utils.matrix_to_pdb(utils.get_seq_aa(os.path.join(\"/content/drive/MyDrive/Ex4Data\", \"6xw6.pdb\"), \"H\")[0], prediction[0, :, :],\"our_6xw6\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/60\n",
            "50/50 [==============================] - 19s 73ms/step - loss: 32.4471 - val_loss: 15.9820\n",
            "Epoch 2/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 4.3150 - val_loss: 14.1350\n",
            "Epoch 3/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 3.1385 - val_loss: 5.9192\n",
            "Epoch 4/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 2.6153 - val_loss: 3.6503\n",
            "Epoch 5/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 2.2786 - val_loss: 2.7976\n",
            "Epoch 6/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 2.1765 - val_loss: 2.4279\n",
            "Epoch 7/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.9915 - val_loss: 1.8809\n",
            "Epoch 8/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.7729 - val_loss: 1.9739\n",
            "Epoch 9/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.7613 - val_loss: 1.6856\n",
            "Epoch 10/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.5917 - val_loss: 1.2947\n",
            "Epoch 11/60\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 1.4981 - val_loss: 1.4012\n",
            "Epoch 12/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.4215 - val_loss: 1.2110\n",
            "Epoch 13/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.3418 - val_loss: 1.1869\n",
            "Epoch 14/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.3162 - val_loss: 1.4545\n",
            "Epoch 15/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.3066 - val_loss: 1.3493\n",
            "Epoch 16/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.2299 - val_loss: 1.1581\n",
            "Epoch 17/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.1983 - val_loss: 1.1277\n",
            "Epoch 18/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.1848 - val_loss: 1.0661\n",
            "Epoch 19/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.1748 - val_loss: 1.1109\n",
            "Epoch 20/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 1.1224 - val_loss: 1.0852\n",
            "Epoch 21/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.0998 - val_loss: 1.0245\n",
            "Epoch 22/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.0995 - val_loss: 1.0553\n",
            "Epoch 23/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.0702 - val_loss: 1.0374\n",
            "Epoch 24/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 1.0637 - val_loss: 1.0374\n",
            "Epoch 25/60\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 1.0167 - val_loss: 0.9779\n",
            "Epoch 26/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.9912 - val_loss: 0.9805\n",
            "Epoch 27/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.9892 - val_loss: 0.9478\n",
            "Epoch 28/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.9804 - val_loss: 1.0514\n",
            "Epoch 29/60\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.9652 - val_loss: 1.0483\n",
            "Epoch 30/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.9474 - val_loss: 0.9674\n",
            "Epoch 31/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.9220 - val_loss: 0.9865\n",
            "Epoch 32/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.9513 - val_loss: 1.1432\n",
            "Epoch 33/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.9041 - val_loss: 0.9530\n",
            "Epoch 34/60\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.8982 - val_loss: 1.0639\n",
            "Epoch 35/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.9064 - val_loss: 0.9306\n",
            "Epoch 36/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.9039 - val_loss: 0.9407\n",
            "Epoch 37/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.9080 - val_loss: 0.9025\n",
            "Epoch 38/60\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.8727 - val_loss: 0.9582\n",
            "Epoch 39/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.8643 - val_loss: 0.9533\n",
            "Epoch 40/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.8819 - val_loss: 1.0110\n",
            "Epoch 41/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.9046 - val_loss: 1.0033\n",
            "Epoch 42/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.8639 - val_loss: 1.0980\n",
            "Epoch 43/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.8491 - val_loss: 1.0852\n",
            "Epoch 44/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.8394 - val_loss: 1.0927\n",
            "Epoch 45/60\n",
            "50/50 [==============================] - 2s 36ms/step - loss: 0.8613 - val_loss: 0.9953\n",
            "Epoch 46/60\n",
            "50/50 [==============================] - 2s 37ms/step - loss: 0.8354 - val_loss: 0.9350\n",
            "Epoch 47/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.8091 - val_loss: 0.9047\n",
            "Epoch 48/60\n",
            "50/50 [==============================] - 2s 46ms/step - loss: 0.8018 - val_loss: 0.9489\n",
            "Epoch 49/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.7869 - val_loss: 0.8955\n",
            "Epoch 50/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.8078 - val_loss: 0.9135\n",
            "Epoch 51/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.7984 - val_loss: 1.0062\n",
            "Epoch 52/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.7938 - val_loss: 1.0138\n",
            "Epoch 53/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.7895 - val_loss: 0.9105\n",
            "Epoch 54/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.7956 - val_loss: 0.9261\n",
            "Epoch 55/60\n",
            "50/50 [==============================] - 2s 33ms/step - loss: 0.7693 - val_loss: 0.9336\n",
            "Epoch 56/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.7627 - val_loss: 0.9109\n",
            "Epoch 57/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.7520 - val_loss: 0.9220\n",
            "Epoch 58/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.7457 - val_loss: 0.9495\n",
            "Epoch 59/60\n",
            "50/50 [==============================] - 2s 34ms/step - loss: 0.7562 - val_loss: 0.9541\n",
            "Epoch 60/60\n",
            "50/50 [==============================] - 2s 35ms/step - loss: 0.7563 - val_loss: 0.8753\n",
            "INFO:tensorflow:Assets written to: my_model.tf/assets\n"
          ]
        }
      ]
    }
  ]
}